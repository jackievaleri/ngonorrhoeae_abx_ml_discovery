{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c31124c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import subprocess\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tqdm\n",
    "\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import DataStructs\n",
    "from rdkit import SimDivFilters\n",
    "\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn import metrics"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a32a0cdf",
   "metadata": {},
   "source": [
    "# First collect the data we'll be working with and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6256f4dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>SMILES</th>\n",
       "      <th>hit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BRD-K93123848</td>\n",
       "      <td>Cn1c(nc2cc(ccc12)Oc1ccnc(c1)-c1ncc([nH]1)C(F)(...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BRD-K30309936</td>\n",
       "      <td>C[C@H]1CCCCO[C@H](CN(C)Cc2ccc(cc2)C(F)(F)F)[C@...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TRIMETHADIONE</td>\n",
       "      <td>CN1C(=O)OC(C)(C)C1=O</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BRD-K76424103</td>\n",
       "      <td>C[C@]1([C@@H](N(Cc2ccccc2)C(=O)c2ccccc21)c1ccc...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BRD-K65130196</td>\n",
       "      <td>CC(C)(C)NCCCCOc1ccc(cc1C(C)(C)C)Cl</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30962</th>\n",
       "      <td>BRD-K24978625</td>\n",
       "      <td>N[C@@H]1CC[C@@H](CCn2cc(nn2)C2CCCCC2)O[C@H]1CO</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30963</th>\n",
       "      <td>BRD-K16976282</td>\n",
       "      <td>C[C@H]1CCCCO[C@H](CN(C)S(=O)(=O)C)[C@@H](C)CN(...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30964</th>\n",
       "      <td>BRD-K53638538</td>\n",
       "      <td>O[C@@H]1CCCC[C@H]1O</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30965</th>\n",
       "      <td>BRD-K77119472</td>\n",
       "      <td>CO[C@@H]1CN(C)C(=O)c2cc(ccc2OC[C@H](C)N(C[C@@H...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30966</th>\n",
       "      <td>BRD-K65833888</td>\n",
       "      <td>C[C@@H]1CN([C@H](C)CO)C(=O)Cc2cc(ccc2O[C@H]1CN...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30967 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Name                                             SMILES  hit\n",
       "0      BRD-K93123848  Cn1c(nc2cc(ccc12)Oc1ccnc(c1)-c1ncc([nH]1)C(F)(...  1.0\n",
       "1      BRD-K30309936  C[C@H]1CCCCO[C@H](CN(C)Cc2ccc(cc2)C(F)(F)F)[C@...  1.0\n",
       "2      TRIMETHADIONE                               CN1C(=O)OC(C)(C)C1=O  1.0\n",
       "3      BRD-K76424103  C[C@]1([C@@H](N(Cc2ccccc2)C(=O)c2ccccc21)c1ccc...  1.0\n",
       "4      BRD-K65130196                 CC(C)(C)NCCCCOc1ccc(cc1C(C)(C)C)Cl  1.0\n",
       "...              ...                                                ...  ...\n",
       "30962  BRD-K24978625     N[C@@H]1CC[C@@H](CCn2cc(nn2)C2CCCCC2)O[C@H]1CO  0.0\n",
       "30963  BRD-K16976282  C[C@H]1CCCCO[C@H](CN(C)S(=O)(=O)C)[C@@H](C)CN(...  0.0\n",
       "30964  BRD-K53638538                                O[C@@H]1CCCC[C@H]1O  0.0\n",
       "30965  BRD-K77119472  CO[C@@H]1CN(C)C(=O)c2cc(ccc2OC[C@H](C)N(C[C@@H...  0.0\n",
       "30966  BRD-K65833888  C[C@@H]1CN([C@H](C)CO)C(=O)Cc2cc(ccc2O[C@H]1CN...  0.0\n",
       "\n",
       "[30967 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets use the 37K+PK data as our training data\n",
    "df = pd.read_csv('../data/data_prep_for_ml/data_prep_for_ml_pk_37k_screen/TRAIN_03_19_2022.csv')\n",
    "\n",
    "# we'll hold out a random set from here for testing - 20% test set will be sufficient since it is random and class balanced\n",
    "# so for testing, use '../data/TEST_03_19_2022.csv'\n",
    "\n",
    "# we'll also test on all the validation molecules we have predicted on since their scaffolds are quite different- easy,med,hard,molport\n",
    "# so for testing, use '../data/cleaned_easy_med_hard_val_sets_800k_10_03_2022.csv'\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f64436a6",
   "metadata": {},
   "source": [
    "# Let's split into sets where we have different proportions of positive:negative data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c69c1b8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive samples: 1017.0\n",
      "Negative samples: 29950.0\n",
      "Negative to positive ratio: 29.449360865290068\n",
      "Number of negatives to test: [508, 1017, 2034, 4068, 8136, 16272, 29950]\n",
      "Number of positives to test: [17, 34, 69, 138, 276, 552, 1017]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[21:16:29] Unusual charge on atom 0 number of radical electrons set to zero\n",
      "100%|██████████| 29950/29950 [00:03<00:00, 8543.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing with 17 positives and 508 negatives\n",
      "Testing with 34 positives and 1017 negatives\n",
      "Testing with 69 positives and 2034 negatives\n",
      "Testing with 138 positives and 4068 negatives\n",
      "Testing with 276 positives and 8136 negatives\n",
      "Testing with 552 positives and 16272 negatives\n",
      "Testing with 1017 positives and 29950 negatives\n"
     ]
    }
   ],
   "source": [
    "# Original negative sample sizes\n",
    "num_neg = [508, 1017, 2034, 4068, 8136, 16272, 29950]\n",
    "\n",
    "# Calculate the ratio of negative to positive in the original dataframe\n",
    "total_pos = sum(df['hit'])\n",
    "total_neg = len(df) - total_pos\n",
    "neg_to_pos_ratio = total_neg / total_pos\n",
    "\n",
    "print('Positive samples:', total_pos)\n",
    "print('Negative samples:', total_neg)\n",
    "print('Negative to positive ratio:', neg_to_pos_ratio)\n",
    "\n",
    "# Calculate the corresponding number of positive samples for each dataset size\n",
    "num_pos = [int(neg / neg_to_pos_ratio) for neg in num_neg]\n",
    "\n",
    "assert all(abs((neg / pos) - neg_to_pos_ratio) < 0.5 for neg, pos in zip(num_neg, num_pos)), \\\n",
    "    \"Positive-to-negative ratio in subsets does not match the original ratio!\"\n",
    "\n",
    "print('Number of negatives to test:', num_neg)\n",
    "print('Number of positives to test:', num_pos)\n",
    "\n",
    "out_dir = '../out/experiment_to_test_different_negative_datasets_class_balanced/'\n",
    "\n",
    "# Preprocess positive and negative data\n",
    "negative_options = df[df['hit'] == 0.0]\n",
    "positive_options = df[df['hit'] == 1.0]\n",
    "\n",
    "all_neg_fps = [Chem.RDKFingerprint(Chem.MolFromSmiles(smi)) for smi in list(negative_options['SMILES'])]\n",
    "all_pos_fps = [Chem.RDKFingerprint(Chem.MolFromSmiles(smi)) for smi in list(positive_options['SMILES'])]\n",
    "\n",
    "# Preprocess sorted indices for second method of selection (most similar to positive)\n",
    "tan_sims_from_all_neg_to_pos = [\n",
    "    max(DataStructs.BulkTanimotoSimilarity(query_fp, all_pos_fps)) for query_fp in tqdm.tqdm(all_neg_fps)\n",
    "]\n",
    "sorted_indices_most_similar = np.argsort([1.0 - x for x in tan_sims_from_all_neg_to_pos])  # Most similar to least similar\n",
    "\n",
    "for neg_count, pos_count in zip(num_neg, num_pos):\n",
    "    print(f'Testing with {pos_count} positives and {neg_count} negatives')\n",
    "\n",
    "    # First method: random negatives\n",
    "    rand_neg = negative_options.sample(n=neg_count, replace=False)\n",
    "    rand = pd.concat([rand_neg, positive_options.sample(n=pos_count)]).sample(frac=1)\n",
    "    rand.to_csv(out_dir + f'random_pos_{pos_count}_neg_{neg_count}.csv', index=False)\n",
    "\n",
    "    # Second method: most similar negatives\n",
    "    set_of_sorted_similar_indices = sorted_indices_most_similar[:neg_count]\n",
    "    similar_neg = negative_options.iloc[set_of_sorted_similar_indices]\n",
    "    similar = pd.concat([similar_neg, positive_options.sample(n=pos_count)]).sample(frac=1)\n",
    "    similar.to_csv(out_dir + f'similar_pos_{pos_count}_neg_{neg_count}.csv', index=False)\n",
    "\n",
    "    # # for proof that it's kinda random: \n",
    "    # dist_hist=[]\n",
    "    # for i in range(len(set_of_sorted_similar_indices)):\n",
    "    #     for j in range(i+1,len(set_of_sorted_similar_indices)):\n",
    "    #         dist_hist.append(DataStructs.TanimotoSimilarity(all_neg_fps[set_of_sorted_similar_indices[i]],all_neg_fps[set_of_sorted_similar_indices[j]]))\n",
    "    # plt.hist(dist_hist, label = 'random')\n",
    "\n",
    "    # Third method: most diverse negatives\n",
    "    mmp = SimDivFilters.MaxMinPicker()\n",
    "    diverse_indices = mmp.LazyBitVectorPick(all_neg_fps, len(all_neg_fps), neg_count)\n",
    "    diverse_neg = negative_options.iloc[diverse_indices]\n",
    "    diverse = pd.concat([diverse_neg, positive_options.sample(n=pos_count)]).sample(frac=1)\n",
    "    diverse.to_csv(out_dir + f'diverse_pos_{pos_count}_neg_{neg_count}.csv', index=False)\n",
    "    \n",
    "    # # for proof that it's diverse: \n",
    "    # dist_hist=[]\n",
    "    # for i in range(len(diverse_indices)):\n",
    "    #     for j in range(i+1,len(diverse_indices)):\n",
    "    #         dist_hist.append(DataStructs.TanimotoSimilarity(all_neg_fps[diverse_indices[i]],all_neg_fps[diverse_indices[j]]))\n",
    "    # plt.hist(dist_hist, label = 'diverse')\n",
    "    # plt.legend()\n",
    "    # plt.show()\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "977c2522",
   "metadata": {},
   "source": [
    "# Prep script to train models on these different datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16daffa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "bash_dir = 'experiment_to_test_diff_neg_datasets_train_models_class_balanced.sh'\n",
    "\n",
    "for neg_count, pos_count in zip(num_neg, num_pos):\n",
    "    for j in ['random', 'similar', 'diverse']:\n",
    "        # Skip non-random methods for the largest dataset\n",
    "        if neg_count == len(df) - num_pos[-1] and j != 'random':\n",
    "            continue\n",
    "        \n",
    "        # Updated clean_name to include both positive and negative counts\n",
    "        clean_name = f\"{j}_pos_{pos_count}_neg_{neg_count}\"\n",
    "        \n",
    "        # Updated folder and file paths to use the new naming convention\n",
    "        fold = f'models/experiment_with_diff_neg_datasets_class_balanced/{clean_name}/'\n",
    "        mk_folder_command = f'mkdir -p {fold}'  # Use -p to avoid errors if the folder exists\n",
    "        train_command = (\n",
    "            f'chemprop_train --dropout 0.1 --hidden_size 500 --ffn_num_layers 2 --depth 3 '\n",
    "            f'--metric prc-auc --extra_metrics auc --save_dir {fold} '\n",
    "            f'--data_path out/experiment_to_test_different_negative_datasets_class_balanced/{clean_name}.csv '\n",
    "            f'--dataset_type classification --features_generator rdkit_2d_normalized --no_features_scaling '\n",
    "            f'--num_folds 5 --ensemble_size 2 --split_type scaffold_balanced --split_sizes 0.8 0.1 0.1 '\n",
    "            f'--smiles_columns SMILES --target_columns hit --gpu 0'\n",
    "        )\n",
    "        \n",
    "        # Write the commands to the bash script\n",
    "        with open(bash_dir, \"a\") as file1:\n",
    "            file1.write(mk_folder_command + '; ' + train_command + '\\n')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "81f2adf7",
   "metadata": {},
   "source": [
    "# Use different neg dataset models to predict on 20% random test set + external val set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "purple-finnish",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "activate_command = 'conda activate chemprop; '\n",
    "out_path = '../melis_gonorrhea/out/experiment_to_test_different_negative_datasets_class_balanced/'\n",
    "\n",
    "for neg_count, pos_count in zip(num_neg, num_pos):  # Use num_pos calculated earlier\n",
    "    for j in ['random', 'similar', 'diverse']:\n",
    "        for data_name, data in zip(['external_val', '20%_random_test'], \n",
    "                                   ['cleaned_easy_med_hard_val_sets_800k_10_03_2022.csv', \n",
    "                                    'TEST_03_19_2022.csv']):\n",
    "            # Updated clean_name to include both positive and negative counts\n",
    "            clean_name = f\"{j}_pos_{pos_count}_neg_{neg_count}\"\n",
    "            try:\n",
    "                # Updated file path to reflect the new naming convention\n",
    "                testdf = pd.read_csv(\n",
    "                    f'../out/experiment_to_test_different_negative_datasets_class_balanced/pred_{data_name}_{clean_name}.csv'\n",
    "                )\n",
    "                continue  # already exists\n",
    "            except FileNotFoundError:\n",
    "                print(clean_name, data)\n",
    "                run_command = (\n",
    "                    f'python predict.py --test_path {out_path}{data} '\n",
    "                    f'--checkpoint_dir ../melis_gonorrhea/models/experiment_with_diff_neg_datasets_class_balanced/{clean_name}/ '\n",
    "                    f'--preds_path {out_path}pred_{data_name}_{clean_name}.csv '\n",
    "                    f'--features_generator rdkit_2d_normalized --no_features_scaling --smiles_column SMILES '\n",
    "                    f'--ensemble_variance --gpu 0'\n",
    "                )\n",
    "                full_command = activate_command + run_command\n",
    "                test = subprocess.run(full_command, cwd=\"../../chemprop/\", shell=True, capture_output=True)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "87e1cc24",
   "metadata": {},
   "source": [
    "# Quantify predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1067edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modeleval(y_true, y_pred, name = ''):\n",
    "    \n",
    "    # Compute auROC \n",
    "    auroc = float(roc_auc_score(y_true, y_pred))\n",
    "    \n",
    "    # Compute Precision-Recall\n",
    "    precision, recall, thresholds = precision_recall_curve(y_true, y_pred)\n",
    "    pr = float(auc(recall,precision))\n",
    "\n",
    "    return(auroc, pr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c4bdecd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../out/experiment_to_test_different_negative_datasets_class_balanced/'\n",
    "columns = ['N (negatives)', 'Data Selection', 'Test Set', 'Metric', 'Value']\n",
    "results = pd.DataFrame(columns=columns)\n",
    "\n",
    "for neg_count, pos_count in zip(num_neg, num_pos):  # Use num_pos calculated earlier\n",
    "    for j in ['random', 'similar', 'diverse']:\n",
    "        for data_name, data in zip(['external_val', '20%_random_test'], \n",
    "                                   ['cleaned_easy_med_hard_val_sets_800k_10_03_2022.csv', \n",
    "                                    'TEST_03_19_2022.csv']):\n",
    "            # Updated clean_name to include both positive and negative counts\n",
    "            clean_name = f\"{j}_pos_{pos_count}_neg_{neg_count}\"\n",
    "            \n",
    "            true_path = f\"{data_dir}{data}\"\n",
    "            pred_path = f\"{data_dir}pred_{data_name}_{clean_name}.csv\"\n",
    "            \n",
    "            try:\n",
    "                true = pd.read_csv(true_path)\n",
    "                true = list(true['hit'])\n",
    "\n",
    "                test = pd.read_csv(pred_path)\n",
    "                test = list(test['hit'])\n",
    "            except FileNotFoundError:\n",
    "                continue\n",
    "\n",
    "            # Calculate metrics\n",
    "            roc, pr = modeleval(true, test)\n",
    "            \n",
    "            # Prepare rows for results\n",
    "            row1 = [neg_count, j, data_name, 'auROC', roc]\n",
    "            row2 = [neg_count, j, data_name, 'auPR', pr]\n",
    "            new = pd.DataFrame([row1, row2], columns=columns)\n",
    "            \n",
    "            # Append results\n",
    "            results = pd.concat([results, new], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e47ea41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename for plotting\n",
    "results['Test Set'] = ['Restricted Similarity' if x=='external_val' else 'Random (20%)' for x in list(results['Test Set'])]\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885a4b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_path = '../figure_panels/negative_dataset_example_class_balanced'\n",
    "results = results.reset_index(drop = True)\n",
    "order = ['random', 'similar', 'diverse']\n",
    "palette = dict(zip(order, ['grey', 'lightsteelblue', 'royalblue']))\n",
    "sns.set(rc={\"figure.dpi\":300, 'savefig.dpi':300})\n",
    "sns.set_style(\"whitegrid\", {'axes.grid' : False})\n",
    "g = sns.FacetGrid(results, row = 'Metric', col = 'Test Set', sharey = True, height=4, aspect=1.5, margin_titles=True)\n",
    "g.map(sns.lineplot, 'N (negatives)', 'Value', 'Data Selection', marker = 'o', dashes=True, hue_order = order, palette = palette)\n",
    "\n",
    "for ax in g.axes_dict.values():\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "g.set(xscale='log')\n",
    "g.set(xticks=num_neg)\n",
    "g.set(xticklabels=num_neg)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(fig_path + '.png')\n",
    "plt.savefig(fig_path + '.svg')  \n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chemprop",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
